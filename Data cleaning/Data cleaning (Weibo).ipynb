{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdab3923-a27b-4009-ac30-1e202f58a987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook includes several rounds of data cleaning for Weibo data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339b7bd3-12ab-4202-ba78-9299f4be1d2e",
   "metadata": {},
   "source": [
    "# Preliminary data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4c3adb-7d38-4988-be26-601d4ee095c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a613fbf9-9115-42d4-abf2-067953399f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../all_tweets.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c474f25e-5e30-44d0-9019-c8b65ef3c41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cae0a05-fcaa-4932-aa60-c9cd3e906b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up duplicated posts\n",
    "# Filter user_id that occurrs in more than one rows\n",
    "\n",
    "# Group by 'user_id' and count occurrences\n",
    "user_id_counts = df['user_id'].value_counts()\n",
    "print(user_id_counts)\n",
    "\n",
    "# Filter user_ids that occur more than once\n",
    "duplicate_user_ids = user_id_counts[user_id_counts > 1].index\n",
    "\n",
    "# number of duplicated user_ids\n",
    "print('number of duplicated user_ids:', len(duplicate_user_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251971d5-2ce1-4ec5-a142-4d1e60d9cc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dup_ids = df[df['user_id'].isin(duplicate_user_ids)]\n",
    "print(df_dup_ids.info())\n",
    "# df_dup_ids.to_excel('../tweets_with_same_userid.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0795d38b-173c-425b-b83b-b54912ba3ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return the row with the longest 'content_long' with the same \"user_id\"\n",
    "def longest_content(group):\n",
    "    return group.loc[group['content_long'].str.len().idxmax()]\n",
    "\n",
    "# Apply the function to each group of 'user_id'\n",
    "df_unique = df.groupby('user_id').apply(longest_content).reset_index(drop=True)\n",
    "df_unique.info()\n",
    "# df_unique.to_excel('../all_tweets_unique_userid.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5cd0da-3d15-412d-869e-04a0230aed93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_duplicate = df[~df['mblogid'].isin(df_unique['mblogid'])]\n",
    "df_duplicate.info()\n",
    "# df_duplicate.to_excel('../all_tweets_duplicate_userid.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af108032-f734-4131-84e2-a7d0de2fd6f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop tweets that are likely to be fictions\n",
    "\n",
    "fiction_keywords = '书名|小说'\n",
    "fiction = df_unique['content_long'].str.contains(fiction_keywords)\n",
    "print(fiction.value_counts())\n",
    "# df_unique[fiction].to_excel('../fiction_tweets.xlsx')\n",
    "df_clean = df_unique[~fiction]\n",
    "print(df_clean.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbd697a-8b2e-412e-8726-5e6a9de3ea12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop user_ids that contain “平安XX”, “XX公安局”, “XX公安”， “网警\"\n",
    "police_keywords = '平安|公安局|公安|网警'\n",
    "police_account = df_clean['user_nickname'].str.contains(police_keywords)\n",
    "print(police_account.value_counts())\n",
    "# df_clean[police_account].to_excel('../police_tweets.xlsx')\n",
    "df_clean = df_clean[~police_account]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2143c6-1075-49f6-91d2-23c2e2b90be4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test\n",
    "print(df_clean['user_nickname'].str.contains('律师').value_counts())\n",
    "df_clean[df_clean['user_nickname'].str.contains('律师')]['content_long']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959c68bb-76b1-4aca-9fe4-e1d7d908abaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually read some tweets to identify patterns of (irrelevance) and record tweet ids\n",
    "id_drop_all = ['1296492494', '1081663190', '1394657835', '1564834725', '1606667657', '1644467702', '1647486362'\n",
    "              '1677318422', '1686117203', '1690286072', '1722262045', '1751193582', '1751845874', '1752221123',\n",
    "               '1770600902', '1772857380', '1784038920', '1804994885', '1811670545', '1821383387', '1844741851',\n",
    "               '1871994611', '1877094373', '1893162821', '1899956213', '1912661142', '1923453581', '1934457620',\n",
    "               '1952359211', '1974576991', '1974890273', '2035996144', '2053886377', '2059048010', '2099262421',\n",
    "               '2132599977', '2150642134', '2165230551', '2257231834', '2299211261', '2309793804', '2310663307',\n",
    "               '2337853855', '2338945183', '2339380177', '2365322025', '2499841932', '2523245097', '2530370612',\n",
    "               '2612002252', '2633812090', '2679119973', '2683684161', '2702325155', '2716784935', '2725689431',\n",
    "               '2786481185', '2839442860', '2885668544', '3442980450',  '3504031483', '3525333977', '3043598067',\n",
    "               '3084859935', '3205272115', '3215052832',\n",
    "               '3627702155'               \n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bda9b2-2b25-4260-9391-a26da007ae7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_keep_all = ['1222221682', '1286131412', '1609734732', '1642385340', '1717833412', '1728892794', '1738111281',\n",
    "               '1791447807', '1845864154', '1856446532', '1887344341', '1903046517', '1926079932', '1961718870',\n",
    "               '1974567457', '1977460817', '1989527362', '2106671735', '2377492125', '2729757644', '3483877775',\n",
    "               '3151530492', '7841362555'             \n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e071ff-72d3-41ce-8887-0972126f5a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop tweets from all tweets if user_id is in id_drop_all\n",
    "df_clean = df_clean[~df_clean['user_id'].isin(id_drop_all)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91058140-9687-4990-a0c0-23780fa50e1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_clean['content_long']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2f9c28-4956-4dff-9127-082f1d7136a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up noises: \"@XXX \", \"//@XXX:\", \"http://t.cn/XXX\", \"\\n\", \"[XX]\", \"#XX#\"\n",
    "import re\n",
    "pattern = r'//@\\S+:|http://t\\.cn/\\S+|\\n|\\[[^\\]]+\\]'\n",
    "def clean_noises(text):\n",
    "    return re.sub(pattern, '', text)\n",
    "df_clean['content_clean'] = df_clean['content_long'].apply(clean_noises)\n",
    "\n",
    "def clean_mention(text):\n",
    "    return re.sub(r'@\\S+ ', '', text)\n",
    "df_clean['content_clean'] = df_clean['content_clean'].apply(clean_mention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037917fe-cce2-4ff8-93c3-5e049e9010da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further clean up df_unique\n",
    "irrelevant_keywords = '哈哈|嘻嘻|嘿嘿|粉丝|影视|韩剧|黑粉|剧组|艺人|网络黑社会|说一个真事|三建|'\\\n",
    "                        '雇佣军|雇佣兵|俄罗斯|日本|韩国|南韩|美国|香港|印度|墨西哥|泰国|美國|荷兰|'\\\n",
    "                          '狂飙|渣男|扫黑除恶专项斗争|扫黑除恶斗争|电影|主演|N/A|指导意见|皇后|失眠'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86560f61-10b1-468c-b7ea-cc067adc0ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "test = '三建'\n",
    "print(df_clean['content_clean'].str.contains(test).value_counts())\n",
    "df_clean[df_clean['content_clean'].str.contains(test)][['content_clean','user_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0370c6-874f-457e-904c-9ffcec4bf464",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop tweets with irrelevant keywords\n",
    "df_clean = df_clean[~df_clean['content_clean'].str.contains(irrelevant_keywords)]\n",
    "print(df_clean.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37181bdd-b53b-4bd0-af43-aa01396ab85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['length'] = df_clean['content_clean'].apply(lambda x:len(x))\n",
    "df_clean['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4d9e34-d32a-4701-8a6d-5edfb2a472f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "## Principal of cutoff: drop noises as much as possible, may contain a few useful tweets.\n",
    "cutoff = 35\n",
    "short_df = df_clean[df_clean['length'] < cutoff]\n",
    "print(len(short_df))\n",
    "print(short_df['content_clean'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ea66c4-8994-4e0a-96fa-af38c6c6ebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean[~df_clean['mblogid'].isin(short_df['mblogid'])]\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9863d41d-5931-46e7-bf6d-ec58b2aeef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_excel('../for_review.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c0f2a9-18f1-409d-b0b7-23ea550bfa38",
   "metadata": {},
   "source": [
    "# Integrate GPT-cleaned results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5784ce-a791-4161-8755-d938beca1478",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "fpath = Path('gpt_cleaned_data.json')\n",
    "result = json.loads(fpath.read_text())\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bb2e94-d8c6-40ff-b24a-dd1b8ad7ec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_df = pd.DataFrame.from_dict(result, orient='index', columns=['reason','relevance'])\n",
    "gpt_df.reset_index(inplace=True)\n",
    "gpt_df.rename(columns={'index': 'mblogid'}, inplace=True)\n",
    "gpt_df.info()\n",
    "gpt_df['relevance'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df30194a-5f36-477d-956f-6099db3cad3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df and gpt_df by tweet id\n",
    "df_gpt_cleaned = pd.merge(df_clean, gpt_df, how='left', on='mblogid')\n",
    "df_gpt_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf1d467-76dc-41a8-b894-dda4657b03fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in hand coded data\n",
    "# Create a dataframe \n",
    "df_hand_result = pd.DataFrame({\n",
    "    'mblogid': id_list,\n",
    "    'relevance_y': result_list\n",
    "})\n",
    "df_hand_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4951b48-2459-44b3-be9e-99669f00e05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in hand coded data \n",
    "\n",
    "df_clean_final = pd.merge(df_gpt_cleaned, df_hand_result, on='mblogid', how='left')\n",
    "df_clean_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ee15a4-44fc-4e29-b6ea-119c76dcc085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update missing values for \"relevance\" with \"relevance_y\"\n",
    "df_clean_final['relevance'].fillna(df_clean_final['relevance_y'], inplace=True)\n",
    "df_clean_final = df_clean_final.drop('relevance_y', axis=1)\n",
    "df_clean_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd05b2c9-9d73-43dc-9fbe-b8ad50ae1c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_final.to_pickle('../all_tweets_cleaned.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d89ab25-3325-42ae-9543-e44da1db4ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_final['relevance'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4c4ab9-cce5-4d22-b13d-69f44efddbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_final['created_at']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3caede-30ef-41ba-8d2f-0866b312b5b1",
   "metadata": {},
   "source": [
    "# Clean up repetitive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0025dbb6-2de2-4544-a405-9fa8acb9b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.read_pickle('../all_tweets_cleaned.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd76f509-daac-4478-b15c-6dfff058835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415bab3a-ff30-4639-8065-0f90f93e2cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rel = df_clean[df_clean['relevance']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fd1762-b129-4e04-8500-0997e1f734b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f34196-c472-491f-871e-e634a0f29437",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"久拖不解！村霸书记吴惠芳雇佣黑恶势力长期监视跟踪！今8月30日上午我去做核酸，这个蒙面人骑的电瓶车，还有步行的，贺青松开汽车的，他把我拍的视频用高科技对着我的手机删除，这是黑社会在犯法犯罪！这视频变短了很多，为什么敢做不敢当呀？真不要脸！\"\n",
    "text2 = \"#安徽车超冤案# 久拖不解！村霸书记吴惠芳雇佣黑恶势力长期监视跟踪！今8月30日上午我去做核酸，这个蒙面人骑的电瓶车，还有步行的，贺青松开汽车的，他把我拍的视频用高科技对着我的手机删除，这是黑社会在犯法犯罪！这视频变短了很多，为什么敢做不敢当呀？真不要脸！\"\n",
    "text3 = \"扬州是宜居城市养老胜地但不是让你们这些垃圾官员来养老享福的十几轮核酸了还有新增天天有人求助就医、物资等各种问题政府人员小区可以随意调整风险等级还雇佣黑社会当志愿者打人明天不知道又有什么新惊喜等着扬州市民呢\"\n",
    "\n",
    "from Levenshtein import distance\n",
    "print(distance(text1, text2))\n",
    "print(distance(text1, text3))\n",
    "\n",
    "from Levenshtein import ratio\n",
    "print(ratio(text1, text2))\n",
    "print(ratio(text1, text3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c33b61e-62d3-4989-a102-c39100844e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from Levenshtein import distance\n",
    "import numpy as np\n",
    "\n",
    "def levenshtein_distance_matrix(strings):\n",
    "    n = len(strings)\n",
    "    # Initialize an n x n matrix with zeros\n",
    "    matrix = np.zeros((n, n), dtype=np.float64)\n",
    "\n",
    "    for i in tqdm(range(n)):\n",
    "        for j in range(i+1, n):\n",
    "            matrix[i, j] = ratio(strings[i], strings[j])\n",
    "\n",
    "    return matrix\n",
    "\n",
    "# Get the column as a list\n",
    "column_list = df_rel['content_clean'].tolist()\n",
    "\n",
    "# Calculate the matrix\n",
    "distance_matrix = levenshtein_distance_matrix(column_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2444bdad-c247-4b0a-a67d-92567dfc00e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(column_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32822d81-f5a3-4290-8bd8-4bc0cd45c70a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = distance_matrix.flatten()\n",
    "scores = scores[scores > 0.2]\n",
    "\n",
    "# plot histogram of scores\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306933b6-4807-4b51-a1c3-b13df3901047",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7b3589-687f-4016-8418-c5bd33f2fd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find indices where the elements are at least 0.9\n",
    "rows, cols = np.where(distance_matrix > 0.4)\n",
    "\n",
    "kept = set(range(len(df_rel)))\n",
    "for i, j in zip(rows, cols):\n",
    "    if i in kept and j in kept:\n",
    "        if len(column_list[i]) < len(column_list[j]):\n",
    "            kept.remove(i)\n",
    "        else:\n",
    "            kept.remove(j)\n",
    "\n",
    "df_kept = df_rel.iloc[sorted(kept)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ca367e-81fd-4480-994c-0640517a9713",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3925c6-b28a-4e4d-9e8e-8ad552e1cdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095ceb00-c7c1-4c85-8501-a132efc6641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "1737*1737"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618e9530-b012-47d1-bb86-3cba76d5009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(column_list[42])\n",
    "print(column_list[524])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d310dac-bd66-4871-af09-229138c53f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output.txt\", \"w\") as f:\n",
    "    for row, col in zip(rows, cols):\n",
    "        f.write(f'Index: ({row}, {col}), Value: {distance_matrix[row, col]}\\n')\n",
    "        f.write(f'{column_list[row]}\\n')\n",
    "        f.write(f'{column_list[col]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f91b54c-ccce-4e9b-a0a6-8aef3f202b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.to_pickle('../all_tweets_cleaned_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5420effd-bad4-45eb-b8ed-a1c16287ee52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
