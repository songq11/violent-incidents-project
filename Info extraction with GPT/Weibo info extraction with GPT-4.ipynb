{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee939a4-faf4-47f8-b1f7-bfe610aaf4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook uses GPT-4 API to extract key information from Weibo data\n",
    "# Kai Jia (https://jiakai.xyz/) has contributed to the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7fa41e-6d9a-4c0e-81ef-38167217f202",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI, AsyncOpenAI\n",
    "import asyncio\n",
    "import re\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "class GPTQuery:\n",
    "    system_prompt = \"\"\"You are an expert in the Chinese language and in Chinese politics. Answer all the questions from the user as accurately as possible.\"\"\"\n",
    "    log_filename = '../gpt-query-log.txt'\n",
    "    \n",
    "    prompt: str\n",
    "    client: AsyncOpenAI\n",
    "\n",
    "    _json_locator = re.compile(r'```json(.*)```', flags=re.DOTALL)\n",
    "\n",
    "    _json_fixer: \"GPTQuery\" = None\n",
    "    _log_file = None\n",
    "\n",
    "    def __init__(self, prompt: str, system_prompt=None):\n",
    "        self.prompt = prompt\n",
    "        if system_prompt is not None:\n",
    "            self.system_prompt = system_prompt\n",
    "        with open('../openai-key.txt') as fin:\n",
    "            self.client = AsyncOpenAI(api_key=fin.read().strip())\n",
    "\n",
    "    def _print_log(self, msg):\n",
    "        if self._log_file is None:\n",
    "            self._log_file = open(self.log_filename, 'a')\n",
    "            \n",
    "        self._log_file.write(str(msg))\n",
    "        self._log_file.write('\\n')\n",
    "        self._log_file.flush()\n",
    "\n",
    "    def _close_log(self):\n",
    "        if self._log_file is not None:\n",
    "            self._log_file.close()\n",
    "            del self._log_file\n",
    "\n",
    "    @classmethod\n",
    "    def _get_json_fixer(cls):\n",
    "        \"\"\"chatGPT sometimes outputs invalid json. Use itself to fix its output\"\"\"\n",
    "        if cls._json_fixer is None:\n",
    "            cls._json_fixer = cls(\n",
    "                prompt=\"\"\"The following json is invalid. Your task is to fix it to be a valid json. Your response should include the reason why it is invalid, followed by the corrected json. Do not produce any extra response after the corrected json.\"\"\",\n",
    "                system_prompt=\"\"\"You are an expert in computer science. Accurately answer the user's requests.\"\"\"\n",
    "            )\n",
    "        return cls._json_fixer\n",
    "\n",
    "    async def _auto_json_fix(self, jtxt: str) -> dict:\n",
    "        \"\"\"automatically try to fix the json response from GPT\"\"\"\n",
    "        self._print_log(f'!!!! use json fixer: {jtxt}')\n",
    "\n",
    "        if ((start_m := jtxt.find('```')) != -1 and\n",
    "            (end_m := jtxt.find('```', start_m + 3)) != -1):\n",
    "            # ChatGPT occasionally misses the json format marker\n",
    "            try:\n",
    "                return json.loads(jtxt[start_m+3:end_m])\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        if start_m != -1:\n",
    "            # if there are multiple jsons, use the first one\n",
    "            try:\n",
    "                return json.loads(jtxt[:start_m])\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "        if '//' in jtxt:\n",
    "            # remove comments and try again\n",
    "            lines = jtxt.split('\\n')\n",
    "            for i, j in enumerate(lines):\n",
    "                if (cmt_m := j.find('//')) != -1 and '\"' not in j[cmt_m:]:\n",
    "                    lines[i] = j[:cmt_m]\n",
    "            try:\n",
    "                return json.loads('\\n'.join(lines))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        fixer = self._get_json_fixer()\n",
    "        assert self is not fixer  # avoid infinite recursion\n",
    "        return await fixer._query(jtxt)\n",
    "\n",
    "    async def _query(self, query: str) -> dict:\n",
    "        resp = await self.client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "                {\"role\": \"user\", \"content\": f\"{self.prompt}\\n\\n{query}\"}\n",
    "            ]\n",
    "        )\n",
    "        msg = resp.choices[0].message\n",
    "        try:\n",
    "            assert msg.role == 'assistant' and msg.function_call is None and msg.tool_calls is None\n",
    "            self._print_log('============')\n",
    "            self._print_log(query)\n",
    "            txt = msg.content\n",
    "            jtxt_m = self._json_locator.search(txt)\n",
    "            if jtxt_m is None:\n",
    "                jtxt = txt  # gpt sometimes does not wrap the result in json blocks\n",
    "            else:\n",
    "                jtxt = jtxt_m.group(1)\n",
    "            try:\n",
    "                json_succ = False\n",
    "                ret = json.loads(jtxt)\n",
    "                json_succ = True\n",
    "            except:\n",
    "                ret = await self._auto_json_fix(jtxt)\n",
    "                \n",
    "            self._print_log(json.dumps(ret, ensure_ascii=False, indent=2))\n",
    "            if jtxt_m is None or jtxt_m.group(0) != txt or not json_succ:\n",
    "                ret['original_resp'] = txt\n",
    "        except Exception as exc:\n",
    "            raise RuntimeError(f'Query: {query}\\nResp: {msg}') from exc\n",
    "        return ret\n",
    "        \n",
    "    async def query(self, query: str) -> dict:\n",
    "        \"\"\"query a single input, asynchronously\"\"\"\n",
    "        try:\n",
    "            return await self._query(query)\n",
    "        finally:\n",
    "            self._close_log()\n",
    "\n",
    "    async def batch_query(self, concurrency: int, result_file: Path, queries: dict[str, str]):\n",
    "        \"\"\"query multiple inputs concurrently and asynchrously.\n",
    "\n",
    "        :param concurrency: number of concurrent queries allowed\n",
    "        :param result_file: json file to save the results; when a new result arrives, it will be saved immediately. The old result will be read\n",
    "        :param queries: a dict of the queries\n",
    "        \"\"\"\n",
    "        \n",
    "        if not isinstance(result_file, Path):\n",
    "            result_file = Path(result_file)\n",
    "\n",
    "        if result_file.exists():\n",
    "            with result_file.open() as fin:\n",
    "                result = json.load(fin)\n",
    "                print(f'Loaded {len(result)} results')\n",
    "        else:\n",
    "            result = {}\n",
    "\n",
    "        def save_result(force=False):\n",
    "            if (not force) and len(result) % concurrency:\n",
    "                # only save when we get a new batch of results to speed up\n",
    "                return\n",
    "            if result_file.exists():\n",
    "                result_file.rename(result_file.with_suffix('.json.bak'))\n",
    "            with result_file.open('w') as fout:\n",
    "                json.dump(result, fout, ensure_ascii=False, indent=2)\n",
    "            self._print_log(f'******* saved {len(result)} results')\n",
    "\n",
    "        async def one_task(qid):\n",
    "            qres = await self._query(queries[qid])\n",
    "            result[qid] = qres\n",
    "            save_result()\n",
    "\n",
    "        queries = {str(k): v for k, v in queries.items()}\n",
    "        tasks = [one_task(k) for k in queries.keys() if k not in result]\n",
    "\n",
    "        try:\n",
    "            with tqdm(total=len(queries)) as pbar:\n",
    "                pbar.update(len(result))\n",
    "                async for i in self._limit_concurrency(tasks, concurrency):\n",
    "                    await i\n",
    "                    pbar.update(1)\n",
    "        finally:\n",
    "            save_result(True)\n",
    "            self._close_log()\n",
    "\n",
    "    @classmethod\n",
    "    async def _limit_concurrency(cls, aws, limit):\n",
    "        \"\"\"run awaitables with limited concurrency\"\"\"\n",
    "        # see https://death.andgravity.com/limit-concurrency#asyncio-wait\n",
    "        aws = iter(aws)\n",
    "        aws_ended = False\n",
    "        pending = set()\n",
    "    \n",
    "        while pending or not aws_ended:\n",
    "            while len(pending) < limit and not aws_ended:\n",
    "                try:\n",
    "                    aw = next(aws)\n",
    "                except StopIteration:\n",
    "                    aws_ended = True\n",
    "                else:\n",
    "                    pending.add(asyncio.ensure_future(aw))\n",
    "    \n",
    "            if not pending:\n",
    "                return\n",
    "    \n",
    "            done, pending = await asyncio.wait(\n",
    "                pending, return_when=asyncio.FIRST_COMPLETED\n",
    "            )\n",
    "            while done:\n",
    "                yield done.pop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b8c471-ac15-4fe0-84e4-6bfe94778e15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gpt_query = GPTQuery(\n",
    "    \"\"\"You will be provided with a tweet from Weibo in Chinese. The tweet will likely involve narratives of bullying, harassment, or threats by thugs, hooligans, ruffians, gangs, or unorganized stragglers hired by someone else.\n",
    "\n",
    "Your tasks are as follows:\n",
    "\n",
    "1. **Relevance Check:** Determine whether the tweet is relevant to the type of narratives described above. If relevant, continue with the following tasks; otherwise, skip the following information extraction tasks and mark \"relevance\" as \"0\".\n",
    "2. **Information Extraction:** Extract and summarize the key information from the tweet:\n",
    "   - **Perpetrators:** Identify and summarize the identities of the violence perpetrators (e.g., names, organizations, occupations).\n",
    "   - **Victims:** Identify and summarize the identities of the victims (e.g., names, organizations, occupations).\n",
    "   - **Relationships:** Describe the relationships between the perpetrators and the victims.\n",
    "   - **Issue Areas:** Identify the areas of dispute (e.g., commerce, finance, employment).\n",
    "   - **Locations:** Specify the locations mentioned (e.g., province, city, specific places) and categorize them as rural or urban.\n",
    "   - **Degrees of Violence:** Describe the level of violence (e.g., damage, casualties, deaths).\n",
    "\n",
    "3. **Response Format:** Provide your response in well-formed JSON with the following keys:\n",
    "   - `\"reason\"`: A string summarizing your reasoning about the relevance and elements involved.\n",
    "   - `\"relevance\"`: An integer (`1` for relevant, `0` for irrelevant, `-1` if the text is too short or incomplete for evaluation).\n",
    "   - `\"identities of violence perpetrators\"`: A string extracted or interpreted from the text.\n",
    "   - `\"identities of victims\"`: A string extracted or interpreted from the text.\n",
    "   - `\"relationships between perpetrators and victims\"`: A string extracted or interpreted from the text.\n",
    "   - `\"dispute issues\"`: A string extracted or interpreted from the text.\n",
    "   - `\"locations\"`: A string extracted or interpreted from the text.\n",
    "   - `\"rural or urban\"`: A string (`农村` for rural, `城市` for urban, 'NA' if hard to tell).\n",
    "   - `\"degrees of violence\"`: A string extracted or interpreted from the text.\n",
    "\n",
    "4. **Special Cases:**\n",
    "   - If the text is too short or incomplete, mark `\"relevance\"` as `-1`.\n",
    "   - If the event described occurs outside of China, mark `\"relevance\"` as `0`.\n",
    "\n",
    "**IMPORTANT:** The provided text is already the complete post; do not request additional text. Your response must be in Chinese.\n",
    "\n",
    "Below is the text for analysis:\n",
    "\"\"\")\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_excel('tweets_pilot.xlsx')\n",
    "\n",
    "queries = {row['mblogid']: row['content_long'] for _, row in df.iterrows()}\n",
    "\n",
    "await gpt_query.batch_query(32, 'extracted_info.json', queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86a04a7-889c-4fde-ad59-688c2dafdf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_query = GPTQuery(\n",
    "    \"\"\"You will be provided with a tweet from Weibo in Chinese language. The tweet indicates an incident of harassment or violence conducted by thugs or hooligans on behalf of some government or private entities.\n",
    "\n",
    "Your tasks are to determine the categories the tweet belongs that best describe the characteristics of the incident. Provide your response in well-formed JSON with the following keys:\n",
    "   - `\"relevance\"`: Determine whether the tweet describes a real incident of harassment or violence conducted by thugs or hooligans on behalf of some government or private entities. The response should be an integer: `1` for relevant, `0` for irrelevant, fiction, or occurs in countries outside China, `-1` if the text is too short for evaluation.   \n",
    "   - `\"dispute areas\"`: Determine which one of the following areas best describes the dispute issue within this tweet. Your response should be an integer from \"1\" to \"6\" that indicates the best-matching category. If the dispute issue is unspecified, your response should be \"-1\". If the given tweet cannot be categoried into any of the 6 categories, your response should be \"99\".\n",
    "   - `\" perpetrators\"`: Determine which one of the following categories best describes the identities of violence perpetrator. 1. Government officials or local authorities; 2. Businesses and Corporations; 3. Other public sectors (e.g., schools, hospitals). Your response should be an integer from \"1\" to \"3\" that indicates the best-matching category. If the perpetrator is unidentified individuals or groups, your response should be \"-1\". If the given tweet cannot be categoried into any of the 3 categories, your response should be \"99\".\n",
    "   - `\"relationships between perpetrators and victims\"`: Determine which one of the following categories best describes the relationship between violence perpetrator and victim. 1. Government officials vs. citizens; 2. Employment relationships; 3. Commercial relations (e.g., business owners vs. customers, business rivalries); 4. Real estate developers vs. residences; 5. Creditors vs. Debtors. Your response should be an integer from \"1\" to \"5\" that indicates the best-matching category. If the relationship is not specified, your response should be \"-1\". If the given tweet cannot be categoried into any of the 5 categories, your response should be \"99\".\n",
    "   - `\"degrees of violence\"`: Determine which of following categories of violence are involved in this incident. 1. Verbal and psychological intimidation; 2. Property damage; 3. Freedom restriction (e.g., stalking, illegal detention); 4. Physical assult and bodily harm; 5. Property destruction; 6. Life threatening actions and deaths. Your response should be a list that covers all kinds of violence involved. If the degree of violence is not specified, your response should be \"-1\". \n",
    "\n",
    "Below is the text for analysis:\"\"\")\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_parquet('../pilot_data_for_gpt.parquet')\n",
    "\n",
    "queries = {row['mblogid']: row['content_long'] for _, row in df.iterrows()}\n",
    "\n",
    "await gpt_query.batch_query(32, 'extracted_info_pilot.json', queries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adec5f7a-e7a4-4a57-be86-44ef2fb87cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_query = GPTQuery(\n",
    "    \"\"\"You will be provided with a tweet in Chinese. Your task is to determine whether the tweet describes a real-world, violent incident conducted by thugs or hooligans on behalf of some entities or individuals. The incident must happen in China. \n",
    "Provide your response in well-formed JSON with two keys:\n",
    "- “reason”: Your reasoning for the task.\n",
    "- “relevance”:  Your response should be an integer: `1` for relevant, `0` for irrelevant. If the text is a narrative that describes a specific violent incident with clear violent perpetrators and dispute issues, mark it as `1`. If the text describes a fiction, occurs outside China, or is commentary rather than the description of an incident, mark it as `0`.\n",
    "Below is the text for analysis:\"\"\")\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_pickle('../for_gpt_cleaning.pkl')\n",
    "\n",
    "queries = {row['mblogid']: row['content_clean'] for _, row in df.iterrows()}\n",
    "\n",
    "await gpt_query.batch_query(32, 'gpt_cleaned_data.json', queries)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d5f652-2c22-4117-ab72-914f926122ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st layer of classification\n",
    "gpt_query = GPTQuery(\n",
    "    \"\"\"You will be given a Weibo post in Chinese that describes an incident involving harassment or violence by thugs on behalf of certain individuals or entities.\n",
    "\n",
    "Your task is to analyze the causes of violence and categorize the post into one of the following areas:\n",
    "1. Land or housing (e.g., land seizure, forced demolition, residents protests, unfinished housing projects)\n",
    "2. Financial (e.g., fraud, debt, business competition)\n",
    "3. Employment (e.g., unpaid wages, workplace safety)\n",
    "4. Political, policing, or legal (e.g., local election disputes, corruption, police violence)\n",
    "5. COVID-19 (e.g., mentions of \"疫情\", \"口罩\", \"封城\" or similar words)\n",
    "6. Personal conflicts\n",
    "7. Other (if none of the above apply)\n",
    "\n",
    "Provide the response in well-formed JSON format with two keys:\n",
    "- “reason”: Your reasoning for the task.\n",
    "- \"dispute_area\": Return an integer from 1 to 7 that indicates the best-matching category. Your answer must be based on the available information from the post. DO NOT speculate. Return -1 if the disputed issue is unspecified in the text. \n",
    "\n",
    "Text for analysis:\"\"\")\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_pickle('../for_gpt_classification.pkl')\n",
    "\n",
    "queries = {row['mblogid']: row['content_clean'] for _, row in df.iterrows()}\n",
    "\n",
    "await gpt_query.batch_query(32, 'classification_1st_layer.json', queries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ea5f10-04fc-4cf8-acd5-7a38b3114107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd layer of classification -- Class 1: Land or Housing \n",
    "gpt_query = GPTQuery(\"\"\"You will be given a Weibo post in Chinese describing an incident involving harassment or violence by thugs on behalf of certain individuals or entities related to land or housing issues.\n",
    "\n",
    "Your tasks are as follows:\n",
    "Categorize the specific issue in the post into one of these categories:\n",
    "1. Land seizure or forced demolition of houses (e.g., mentions of \"征地\" or \"拆迁\")\n",
    "2. Residents' living rights (e.g., mentions of \"业主\"， \"居民\")\n",
    "3. New or unfinished housing projects (e.g., mentions of “新楼盘”, \"烂尾楼\")\n",
    "4. Others (if none of the above apply)\n",
    "\n",
    "Identify the perpetrator of the violence in the incident from the following categories:\n",
    "1. Government officials or local authorities\n",
    "2. Real estate developers or construction companies\n",
    "3. Property management companies\n",
    "4. Other organizations\n",
    "5. Individuals\n",
    "\n",
    "Your answer must be based on available information from the post. DO NOT speculate. \n",
    "\n",
    "Provide the response in well-formed JSON format with two keys:\n",
    "- \"reason\": Your reasoning for the tasks.\n",
    "- \"specific_issue\": Return an integer from 1 to 5 representing the best-matching category. Return -1 if the specific issue is unclear from the text. \n",
    "- \"perpetrator\": Return an integer from 1 to 5 representing the best-matching category. Return -1 if the specific issue is unclear from the text. \n",
    "\n",
    "Text for analysis:\"\"\")\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_pickle('../for_gpt_class1.pkl')\n",
    "\n",
    "queries = {row['mblogid']: row['content_clean'] for _, row in df.iterrows()}\n",
    "\n",
    "await gpt_query.batch_query(32, 'class_1_issues.json', queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ba6dc6-f902-435d-a713-edc5b42ca39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd layer of classification -- Class 2: Financial\n",
    "gpt_query = GPTQuery(\"\"\"You will be given a Weibo post in Chinese describing an incident involving harassment or violence by thugs on behalf of certain individuals or entities related to financial disputes.\n",
    "\n",
    "Your tasks are as follows:\n",
    "Categorize the specific issue in the post into one of these categories:\n",
    "1. Fraud\n",
    "2. Debt\n",
    "3. Business competition\n",
    "4. Others (if none of the above apply)\n",
    "\n",
    "Identify who hire thugs, i.e., the perpetrator of the violence in the incident from the following categories. \n",
    "1. Government officials or local authorities\n",
    "2. Banks or other financial institutes\n",
    "3. Private companies \n",
    "4. Other organizations\n",
    "5. Individuals\n",
    "\n",
    "Your answer must be based on available information from the post. DO NOT speculate. \n",
    "\n",
    "Provide the response in well-formed JSON format with two keys:\n",
    "- \"reason\": Your reasoning for the tasks.\n",
    "- \"specific_issue\": Return an integer from 1 to 5 representing the best-matching category. Return -1 if the specific issue is unclear from the text. \n",
    "- \"perpetrator\": Return an integer from 1 to 5 representing the best-matching category. Return -1 if the specific issue is unclear from the text. \n",
    "\n",
    "Text for analysis:\"\"\")\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_pickle('../all_tweets_class2.pkl')\n",
    "\n",
    "queries = {row['mblogid']: row['content_clean'] for _, row in df.iterrows()}\n",
    "\n",
    "await gpt_query.batch_query(32, 'class_2_issues.json', queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84e89c9-cffa-4ac1-820c-ff38d6354e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd layer of classification -- Class 4: Political, policing, legal\n",
    "gpt_query = GPTQuery(\"\"\"You will be given a Weibo post in Chinese describing an incident involving harassment or violence by thugs on behalf of certain individuals or entities related to political, policing, or legal issues.\n",
    "\n",
    "Your tasks are as follows:\n",
    "\n",
    "Categorize the specific issue in the post into one of these categories:\n",
    "1. Official corruption  \n",
    "2. Village election \n",
    "3. Policing\n",
    "4. Legal cases\n",
    "5. Others (if none of the above apply)\n",
    "\n",
    "Identify who hire thugs, i.e., the perpetrator of the violence in the incident from the following categories. \n",
    "1. Government officials\n",
    "2. Village authorities \n",
    "3. Polices and auxiliary polices (e.g., mentions of “协管”, \"城管\", \"协警\", \"执法\")\n",
    "4. Legal officials\n",
    "5. Others (if none of the above apply) \n",
    "\n",
    "Your answer must be based on available information from the post. DO NOT speculate. \n",
    "\n",
    "Provide the response in well-formed JSON format with two keys:\n",
    "- \"reason\": Your reasoning for the tasks.\n",
    "- \"specific_issue\": Return an integer from 1 to 5 representing the best-matching category. Return -1 if the specific issue is unclear in the text. \n",
    "- \"perpetrator\": Return an integer from 1 to 5 representing the best-matching category. Return -1 if the perpetrator is specified in the text. \n",
    "\n",
    "Text for analysis:\"\"\")\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_pickle('../all_tweets_class4.pkl')\n",
    "\n",
    "queries = {row['mblogid']: row['content_clean'] for _, row in df.iterrows()}\n",
    "\n",
    "await gpt_query.batch_query(32, 'class_4_issues.json', queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ef91ba-9766-4930-8f59-b4a0bb70e6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_query = GPTQuery(\"\"\"You will be given a Weibo post in Chinese that describes an incident involving harassment or violence by thugs on behalf of certain individuals or entities.\n",
    "    \n",
    "Your third task is to identify whether the incident happens in the rural or urban area:\n",
    "1. Rurual\n",
    "2. Urban\n",
    "\n",
    "Your fourth task is to determine which types of following violence are involved in this incident. \n",
    "1. Verbal intimidation \n",
    "2. Property damage\n",
    "3. Freedom restriction (e.g., stalking, illegal detention)\n",
    "4. Physical assult and harm\n",
    "5. Life threatening actions/deaths\n",
    "\n",
    "Your answer must be based on available information from the post. DO NOT speculate. \n",
    "\n",
    "Provide the response in well-formed JSON format with two keys:\n",
    "- \"reason\": Your reasoning for the tasks.\n",
    "- \"region\": Return an integer from 1 to 2 that indicates the best-matching category. Return -1 if the location is unclear from the text. \n",
    "- \"types_of_violence\": Your response should be a list that covers all kinds of violence involved. If the degree of violence is not specified, your response should be \"-1\". \n",
    "\n",
    "Text for analysis:\"\"\")\n",
    "\n",
    "df = pd.read_pickle('../all_tweets_cleaned_final.pkl')\n",
    "\n",
    "queries = {row['mblogid']: row['content_clean'] for _, row in df.iterrows()}\n",
    "\n",
    "await gpt_query.batch_query(32, 'region&violencetypes.json', queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f079e5-1910-485a-9609-836ebbf80fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gpt_query = GPTQuery(\"\"\"You will be given a Weibo post in Chinese that describes an incident involving harassment or violence by thugs on behalf of certain individuals or entities. Your task is to identify in which province of China this incident happened.\n",
    "\n",
    "Your answer must be based on available information from the post. DO NOT speculate. \n",
    "\n",
    "Provide the response in well-formed JSON format with the key 'province'. Your response should be a string. If the location of this incident is not specified, your response should be \"-1\". \n",
    "\n",
    "Text for analysis:\"\"\")\n",
    "\n",
    "df = pd.read_pickle('../all_tweets_cleaned_final.pkl')\n",
    "\n",
    "queries = {row['mblogid']: row['content_clean'] for _, row in df.iterrows()}\n",
    "\n",
    "await gpt_query.batch_query(32, 'province.json', queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b322b55b-01b5-4127-bea3-e995622e4c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
