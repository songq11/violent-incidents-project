{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6704bec5-4c72-461a-9161-c0efb7312653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook runs regression analysis (Poisson, NB, Quasi-poisson) and robustness checks on the combined violence dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756be7ae-cee2-4685-8680-b24b4daf46c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from patsy import dmatrices\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61befc75-ca99-48af-b5c8-0ae295705918",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../combined datasets/dataset_for_regression.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc51cf0e-f4b6-41de-8d45-0e7d3f5b9824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d94de7-7c0a-422f-97f6-6702ab9ad31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['total_cases_weibo', 'total_protest_num', 'gdp', 'num_of_hired_vio_in_protest', 'total_violence_cases', 'hired_cases', 'hired_ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb708997-b3a0-437a-b18d-5bc669375e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['all_hired_violence'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a37032a-f96b-4561-a1f7-3ce1816d89f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dcbea3-a962-4634-b902-5680caa29901",
   "metadata": {},
   "source": [
    "# Fit Poisson Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b893c073-5cf2-4eb7-aa4a-6c2cb1b33628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_poisson_regression(X, y):\n",
    "    \"\"\"\n",
    "    Fit a poisson regression model using independent variables (X) and the dependent variable (y).\n",
    "\n",
    "    Parameters:\n",
    "    X: IVs\n",
    "    y: DV\n",
    "\n",
    "    Returns:\n",
    "    results: fitted model results.\n",
    "    \"\"\"\n",
    "\n",
    "    # Add a constant as intercept\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    # Define the Poisson model\n",
    "    poisson_model = sm.GLM(y, X, family = sm.families.Poisson())\n",
    "\n",
    "    # Fit the model\n",
    "    results = poisson_model.fit()\n",
    "\n",
    "    # Print the summary of the fitted model\n",
    "    print(results.summary())\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9677a90c-4d61-4e21-bf96-087715499971",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define dependent variable\n",
    "y = df['all_hired_violence']\n",
    "\n",
    "# Define independent variables\n",
    "control_var = ['cpi', 'unemp_rate', 'urbanpop_by_totalpop', 'migpop_by_totalpop', 'gdp_pc']\n",
    "market_var = ['landsale_by_govrev', 'median_land_size']\n",
    "gov_var = ['median_corrup_cases', 'median_audit_cases', 'median_protest_num']\n",
    "statcap_var = ['securityexp_pc', 'govexp_by_gdp', 'govrev_by_gdp']\n",
    "\n",
    "X0 = df[control_var]\n",
    "X_mar =  df[control_var + market_var]\n",
    "X_gov = df[control_var + gov_var]\n",
    "X_statcap = df[control_var + statcap_var]\n",
    "X_full = df[control_var + market_var + gov_var + statcap_var]\n",
    "\n",
    "# Fit models\n",
    "baseline_poisson = fit_poisson_regression(X0, y)\n",
    "market_poisson = fit_poisson_regression(X_mar, y)\n",
    "governance_poisson = fit_poisson_regression(X_gov, y)\n",
    "statcap_poisson = fit_poisson_regression(X_statcap, y)\n",
    "full_poisson = fit_poisson_regression(X_full, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b3e6b3-2e9c-442a-a9a6-c5e78c4e9217",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf0e9d5-90a4-46e3-83e8-ef5a8daabcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def add_pca_component(df, columns, n_components=1, component_name=\"pca_component\"):\n",
    "    \"\"\"\n",
    "    Performs PCA on specified columns of a DataFrame and adds the first principal component as a new column.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): The input DataFrame containing the data.\n",
    "    - columns (list): List of columns to perform PCA on.\n",
    "    - n_components (int): Number of principal components to retain (default is 1).\n",
    "    - component_name (str): Name for the new column with the PCA result.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: The original DataFrame with an additional column for the first principal component.\n",
    "  \n",
    "    \"\"\"\n",
    "    # Step 1: Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(df[columns])\n",
    "\n",
    "    # Step 2: Perform PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_reduced = pca.fit_transform(X_scaled)\n",
    "\n",
    "    # Get the loadings (principal component coefficients for each original feature)\n",
    "    loadings = pd.DataFrame(pca.components_.T, columns=[f'PC{i+1}' for i in range(n_components)], index=columns)\n",
    "\n",
    "    # Add the first principal component to the DataFrame\n",
    "    df[component_name] = X_reduced[:, 0] if n_components == 1 else X_reduced\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114e10ea-66a1-4459-baf4-d38f759527ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_pca_component(df, market_var, n_components = 1, component_name = 'market_pca')\n",
    "df = add_pca_component(df, gov_var, n_components = 1, component_name = 'gov_pca')\n",
    "df = add_pca_component(df, statcap_var, n_components = 1, component_name = 'statcap_pca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf6dc4b-876c-4e8b-bb65-c360166bd6ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca_var = ['market_pca', 'gov_pca', 'statcap_pca']\n",
    "\n",
    "X_pca = df[control_var + pca_var]\n",
    "\n",
    "pca_poisson = fit_poisson_regression(X_pca, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e65a929-0abb-4564-a30b-60d4245dadb6",
   "metadata": {},
   "source": [
    "# Overdispersion Checks for Poisson Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210b037e-4996-4a3e-9751-69eef60bcd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_overdispersion(model):\n",
    "    \"\"\"\n",
    "    Checks for overdispersion in a Poisson regression model using deviance/df.\n",
    "\n",
    "    Parameters:\n",
    "    - model: A fitted Poisson regression model from statsmodels.\n",
    "\n",
    "    Returns:\n",
    "    - Dispersion statistic.\n",
    "    \"\"\"\n",
    "    # Deviance\n",
    "    deviance = model.deviance\n",
    "\n",
    "    # Degrees of freedom\n",
    "    df = model.df_resid\n",
    "\n",
    "    # Calculate dispersion\n",
    "    dispersion = deviance/df\n",
    "    \n",
    "    return dispersion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6075b636-17ed-4559-8073-9ff1dc9a7c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = [baseline_poisson, market_poisson, governance_poisson, statcap_poisson, full_poisson, pca_poisson]\n",
    "\n",
    "for model in all_models:\n",
    "    print(check_overdispersion(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e672e4-e7c3-4fa3-a65e-1ac9cf167ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full model - goodness of fit test\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# Get the expected counts\n",
    "expected_counts = full_poisson.fittedvalues\n",
    "\n",
    "# Compute the Pearson Chi-Square statistic\n",
    "chi_square_stat = np.sum((y - expected_counts) ** 2 / expected_counts)\n",
    "\n",
    "# Compute the degrees of freedom\n",
    "n_observations = len(y)\n",
    "n_parameters = len(full_poisson.params)\n",
    "degrees_of_freedom = n_observations - n_parameters\n",
    "\n",
    "# Compute the p-value\n",
    "p_value = 1 - chi2.cdf(chi_square_stat, degrees_of_freedom)\n",
    "\n",
    "# Print results\n",
    "print(\"Pearson Chi-Square Statistic:\", chi_square_stat)\n",
    "print(\"Degrees of Freedom:\", degrees_of_freedom)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"The model does not fit the data well (reject null hypothesis).\")\n",
    "else:\n",
    "    print(\"The model fits the data well (fail to reject null hypothesis).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38de059-f0d6-466c-a22b-2d6296b626f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that chi-square statistics is larger than the degrees of freedom, indicating overdispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86037bc7-b1c6-48f4-8d0b-afdb1f01eeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot residuals\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(full_poisson.fittedvalues, full_poisson.resid_pearson)\n",
    "\n",
    "# Add horizontal reference lines\n",
    "for h in [-3, -2, 0, 2, 3]:\n",
    "    plt.axhline(y=h, color='red', linestyle='dotted')\n",
    "    \n",
    "plt.xlabel('Fitted Values')\n",
    "plt.ylabel('Pearson Residuals')\n",
    "plt.title('Residuals vs Fitted Values')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c335766a-d384-4057-931a-ab5303222d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine data into a DataFrame for inspection\n",
    "results_df = pd.DataFrame({\n",
    "    'province': df['province'],\n",
    "    'Observed Values': y,\n",
    "    'Fitted Values': full_poisson.fittedvalues,\n",
    "    'Standardized Residuals': full_poisson.resid_pearson})\n",
    "\n",
    "# Define outlier threshold\n",
    "outlier_threshold = 2\n",
    "\n",
    "# Filter rows with standardized residuals above or below the threshold\n",
    "outliers = results_df[(results_df['Standardized Residuals'] > outlier_threshold) |\n",
    "                      (results_df['Standardized Residuals'] < -outlier_threshold)]\n",
    "\n",
    "# Display the rows corresponding to outliers\n",
    "print(outliers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88b9d54-fb45-4fba-859d-3751465746d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot residuals\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(full_poisson_new.fittedvalues, full_poisson_new.resid_pearson)\n",
    "\n",
    "# Add horizontal reference lines\n",
    "for h in [-3, -2, 0, 2, 3]:\n",
    "    plt.axhline(y=h, color='red', linestyle='dotted')\n",
    "    \n",
    "plt.xlabel('Fitted Values')\n",
    "plt.ylabel('Pearson Residuals')\n",
    "plt.title('Residuals vs Fitted Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2271ed6-9616-47d6-a452-eef210199de0",
   "metadata": {},
   "source": [
    "# Drop outlier and rerun poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e609b2c-772b-4323-bfb9-7b11cf62e1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop_outlier = df[df['province'] != 'Hebei']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651344ac-5c41-4b9f-8c23-ad59fb2780a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define dependent variable\n",
    "y_new = df_drop_outlier['all_hired_violence']\n",
    "\n",
    "X0_new = df_drop_outlier[control_var]\n",
    "X_mar_new =  df_drop_outlier[control_var + market_var]\n",
    "X_gov_new = df_drop_outlier[control_var + gov_var]\n",
    "X_statcap_new = df_drop_outlier[control_var + statcap_var]\n",
    "X_full_new = df_drop_outlier[control_var + market_var + gov_var + statcap_var]\n",
    "\n",
    "# Fit models\n",
    "baseline_poisson_new = fit_poisson_regression(X0_new, y_new)\n",
    "market_poisson_new = fit_poisson_regression(X_mar_new, y_new)\n",
    "governance_poisson_new = fit_poisson_regression(X_gov_new, y_new)\n",
    "statcap_poisson_new = fit_poisson_regression(X_statcap_new, y_new)\n",
    "full_poisson_new = fit_poisson_regression(X_full_new, y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b89e217-a753-4456-ad23-7dcf48e651b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check overdispersion\n",
    "all_models_new = [baseline_poisson_new, market_poisson_new, governance_poisson_new, statcap_poisson_new, full_poisson_new]\n",
    "\n",
    "for model in all_models_new:\n",
    "    print(check_overdispersion(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fab06ff-ad1e-45fd-8ad9-2c1bbb1d2beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine data into a DataFrame for inspection\n",
    "results_df = pd.DataFrame({\n",
    "    'province': df_drop_outlier['province'],\n",
    "    'Observed Values': y,\n",
    "    'Fitted Values': full_poisson_new.fittedvalues,\n",
    "    'Standardized Residuals': full_poisson_new.resid_pearson})\n",
    "\n",
    "# Define outlier threshold\n",
    "outlier_threshold = 2\n",
    "\n",
    "# Filter rows with standardized residuals above or below the threshold\n",
    "outliers = results_df[(results_df['Standardized Residuals'] > outlier_threshold) |\n",
    "                      (results_df['Standardized Residuals'] < -outlier_threshold)]\n",
    "\n",
    "# Display the rows corresponding to outliers\n",
    "print(outliers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c582bb69-b8ef-4367-b3ea-a57ce6dbc28d",
   "metadata": {},
   "source": [
    "# Fit Negative Binomial Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cfc48d-545f-4815-a7d8-4649fa0b7c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: https://timeseriesreasoning.com/contents/negative-binomial-regression-model/\n",
    "# https://python.plainenglish.io/a-step-by-step-guide-to-count-data-analysis-in-python-a981544fc4f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d6e3e4-33c8-452e-ab4d-dcac764c5991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_negative_binomial(X, y, alpha):\n",
    "    \"\"\"\n",
    "    Fit a negative binomial model using independent variables (X) and the dependent variable (y).\n",
    "\n",
    "    Parameters:\n",
    "    X: IVs\n",
    "    y: DV\n",
    "\n",
    "    Returns:\n",
    "    results: fitted model results.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the NB2 model, using default value for alpha\n",
    "    nb_model = sm.GLM(y, X, family = sm.families.NegativeBinomial(alpha=alpha))\n",
    "\n",
    "    # Fit the model\n",
    "    results = nb_model.fit()\n",
    "\n",
    "    # Print the summary of the fitted model\n",
    "    print(results.summary())\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f1ec16-ea1f-4811-8996-7469e94c5038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X0_scaled = StandardScaler().fit_transform(X0)\n",
    "X_mar_scaled = StandardScaler().fit_transform(X_mar)\n",
    "X_gov_scaled = StandardScaler().fit_transform(X_gov)\n",
    "X_statcap_scaled = StandardScaler().fit_transform(X_statcap)\n",
    "X_full_scaled = StandardScaler().fit_transform(X_full)\n",
    "X_pca_scaled = StandardScaler().fit_transform(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfec9ea-5c7b-4a0e-a6eb-1c4a40391dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Check for NaN or infinite values in `y`\n",
    "print(\"y contains NaN or Inf:\", np.any(np.isnan(y)) or np.any(np.isinf(y)))\n",
    "\n",
    "# Check for NaN or infinite values in `X_full`\n",
    "print(\"X_gov_scaled contains NaN or Inf:\", np.any(np.isnan(X_full_scaled)) or np.any(np.isinf(X_full_scaled)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dc89d6-e0ab-4783-b5de-12fd7fbca374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit models\n",
    "baseline_nb = fit_negative_binomial(X0_scaled, y, 1)\n",
    "market_nb = fit_negative_binomial(X_mar_scaled, y, 1)\n",
    "governance_nb = fit_negative_binomial(X_gov_scaled, y, 0.5)\n",
    "statcap_nb = fit_negative_binomial(X_statcap_scaled, y, 1)\n",
    "full_nb = fit_negative_binomial(X_full_scaled, y, 0.5)\n",
    "pca_nb = fit_negative_binomial(X_pca_scaled, y, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b1f60d-d9bb-452b-9e6f-26957dc14846",
   "metadata": {},
   "source": [
    "# Negative Binomial Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad651d5d-8930-40cb-97e1-fe382a35a6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log likelihood\n",
    "\n",
    "all_nb_models = [baseline_nb, market_nb, governance_nb, statcap_nb, full_nb, pca_nb]\n",
    "\n",
    "for model_name in all_nb_models:\n",
    "    print(f'loglikelihood: {model_name.llf}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7445e67a-789d-4353-a207-62435e584594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIC BIC\n",
    "\n",
    "for model in all_nb_models:\n",
    "    print(f\"AIC: {model.aic}\")\n",
    "    print(f\"BIC: {model.bic}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae402f5a-44c7-427c-8048-033f3b822e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson Chi-Square Goodness-of-Fit Test\n",
    "\n",
    "from scipy.stats import chi2\n",
    "\n",
    "def get_pearson_chi(model):\n",
    "    \n",
    "    # Calculate observed and predicted values\n",
    "    observed = y\n",
    "    predicted = model.fittedvalues\n",
    "    \n",
    "    # Compute Pearson residuals\n",
    "    pearson_residuals = (observed - predicted) / np.sqrt(predicted)\n",
    "    \n",
    "    # Calculate Pearson Chi-Square statistic\n",
    "    pearson_chi2 = np.sum(pearson_residuals**2)\n",
    "    \n",
    "    # Degrees of freedom\n",
    "    df = model.df_resid\n",
    "    \n",
    "    # Calculate the p-value\n",
    "    p_value = 1 - chi2.cdf(pearson_chi2, df)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Pearson Chi-Square Statistic: {pearson_chi2}\")\n",
    "    print(f\"Degrees of Freedom: {df}\")\n",
    "    print(f\"p-value: {p_value}\")\n",
    "    \n",
    "    # Interpret the fit\n",
    "    if p_value > 0.05:\n",
    "        print(\"The model fits the data well (fail to reject null hypothesis).\")\n",
    "    else:\n",
    "        print(\"The model does not fit the data well (reject null hypothesis).\")\n",
    "\n",
    "for model in all_nb_models:\n",
    "    print(get_pearson_chi(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9eec80-838c-4c6a-93f0-a742d9551ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate McFadden's pseudo-R²\n",
    "\n",
    "for model in all_nb_models:\n",
    "    null_llf = model.llnull  # log-likelihood of the null model\n",
    "    mcfadden_r2 = 1 - (model.llf / null_llf)\n",
    "    print(f\"McFadden's R²: {mcfadden_r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6af4835-3b62-4cf5-970a-adc7be8e9c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In essence, a negative pseudo R square indicates that your model does not explain the data as well as the null model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4debafc6-5fb0-4e54-8710-fd2bba0f2c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot residuals\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(full_nb.fittedvalues, full_nb.resid_pearson)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel('Fitted Values')\n",
    "plt.ylabel('Pearson Residuals')\n",
    "plt.title('Residuals vs Fitted Values')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86006572-59a4-4b71-a78a-c719def88a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot y vs fitted values\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(full_nb.fittedvalues, y)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel('Fitted Values')\n",
    "plt.ylabel('True values')\n",
    "plt.title('True vs Fitted Values')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adfa889-387b-46f4-b1af-11f1e19e6438",
   "metadata": {},
   "source": [
    "# Quasi-poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff55fd2-f941-46c3-963f-637747abe0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate scale (dispersion) factor\n",
    "scale_factor = full_poisson.deviance / full_poisson.df_resid\n",
    "\n",
    "# Refit the model with adjusted standard errors\n",
    "quasi_poisson_results = full_poisson.get_robustcov_results(cov_type='HC0')\n",
    "print(quasi_poisson_results.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a040dbd-0f1a-4c34-ad3e-a53b3a93003a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_quasi_poisson_regression(X, y):\n",
    "    \"\"\"\n",
    "    Fit a poisson regression model using independent variables (X) and the dependent variable (y).\n",
    "\n",
    "    Parameters:\n",
    "    X: IVs\n",
    "    y: DV\n",
    "\n",
    "    Returns:\n",
    "    results: fitted model results.\n",
    "    \"\"\"\n",
    "\n",
    "    # Add a constant as intercept\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    # Define the Poisson model\n",
    "    poisson_model = sm.GLM(y, X, family = sm.families.Poisson())\n",
    "\n",
    "    # Fit the model\n",
    "    results = poisson_model.fit(cov_type='HC0')\n",
    "\n",
    "    # Print the summary of the fitted model\n",
    "    print(results.summary())\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a37d04-a454-400e-8ff8-d27c3a6b70e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit models\n",
    "baseline_q_poisson = fit_quasi_poisson_regression(X0, y)\n",
    "market_q_poisson = fit_quasi_poisson_regression(X_mar, y)\n",
    "governance_q_poisson = fit_quasi_poisson_regression(X_gov, y)\n",
    "statcap_q_poisson = fit_quasi_poisson_regression(X_statcap, y)\n",
    "full_q_poisson = fit_quasi_poisson_regression(X_full, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c593e1-70cd-4c49-a874-719aa9fbc55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_qp_models = [baseline_q_poisson, market_q_poisson, governance_q_poisson, statcap_q_poisson, full_q_poisson]\n",
    "\n",
    "for model in all_qp_models:\n",
    "    print(check_overdispersion(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3a5d3d-6205-49f1-a32a-2c11b9b5bf91",
   "metadata": {},
   "source": [
    "# VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0a8cf8-40c1-4d55-a96b-20325f362396",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "def get_vif(x):\n",
    "    vif = pd.DataFrame()\n",
    "    x = add_constant(x)\n",
    "    vif['variables'] = x.columns\n",
    "    vif['vif'] = [variance_inflation_factor(x.values, i) for i in range(x.shape[1])]\n",
    "    return vif\n",
    "\n",
    "for X in [X0, X_mar, X_gov, X_statcap, X_full]:\n",
    "    print(get_vif(X))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c927c7-db87-4507-ae24-ac116075873c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define dependent variable\n",
    "y = df['all_hired_violence']\n",
    "\n",
    "# Revise independent variables\n",
    "\n",
    "# drop 'urbanpop_by_totalpop' from control variables\n",
    "control_var_new = ['cpi', 'unemp_rate', 'migpop_by_totalpop'] # first two vars reflect overall economic conditions\n",
    "\n",
    "# drop 'landsale_by_govrev'OR 'median_land_size'???  \n",
    "# df['gdp_land_interaction'] = df['gdp_pc'] * df['median_land_size']\n",
    "# df['gdp_landrev_interaction'] = df['gdp_pc'] * df['landsale_by_govrev']\n",
    "df['land_size_rev'] = df['median_land_size'] * df['landsale_by_govrev']\n",
    "# df['land_size_square'] = df['median_land_size'] ** 2\n",
    "market_var_new = ['gdp_pc', 'median_land_size', 'landsale_by_govrev'] # market variables reflect level of urbanization\n",
    "\n",
    "# df['audit_corrup_interaction'] = df['median_corrup_cases'] * df['median_audit_cases']\n",
    "gov_var_new = ['median_corrup_cases', 'median_audit_cases'] # drop 'median_corrup_cases' OR 'median_audit_cases'??? \n",
    "\n",
    "df['log_govrev'] = np.log(df['govrev_by_gdp'])\n",
    "df['sqrt_govrev'] = np.sqrt(df['govrev_by_gdp'])\n",
    "df['reciprocal_govrev'] = 1 / df['govrev_by_gdp']\n",
    "statcap_var_new = ['securityexp_pc', 'govrev_by_gdp'] # drop 'govexp_by_gdp' OR 'govrev_by_gdp'because of collinearity\n",
    "\n",
    "X0_new = df[control_var_new]\n",
    "X_mar_new =  df[control_var_new + market_var_new]\n",
    "X_gov_new = df[control_var_new + gov_var_new]\n",
    "X_statcap_new = df[control_var_new + statcap_var_new]\n",
    "\n",
    "control_reduced = ['unemp_rate', 'migpop_by_totalpop']\n",
    "market_reduced = ['gdp_pc']\n",
    "gov_reduced = ['median_corrup_cases']\n",
    "statcap_reduced = ['securityexp_pc']\n",
    "\n",
    "X_full_new = df[control_reduced + market_reduced + gov_reduced + statcap_reduced]\n",
    "\n",
    "# Fit models\n",
    "baseline_qp_new = fit_quasi_poisson_regression(X0_new, y)\n",
    "market_qp_new = fit_quasi_poisson_regression(X_mar_new, y)\n",
    "governance_qp_new = fit_quasi_poisson_regression(X_gov_new, y)\n",
    "statcap_qp_new = fit_quasi_poisson_regression(X_statcap_new, y)\n",
    "full_qp_new = fit_quasi_poisson_regression(X_full_new, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07244a83-9254-46ca-8034-540d54ce4f42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for X in [X0_new, X_mar_new, X_gov_new, X_statcap_new, X_full_new]:\n",
    "    print(get_vif(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3311360-f9d5-4bdf-957e-5ed6fe4765f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_new_models = [baseline_qp_new, market_qp_new, governance_qp_new, statcap_qp_new, full_qp_new]\n",
    "\n",
    "for model in all_new_models:\n",
    "    # Pseudo log-likelihood (based on Poisson assumption)\n",
    "    log_likelihood = model.llf\n",
    "    \n",
    "    # Calculate Pseudo R^2 (McFadden)\n",
    "    ll_null = sm.GLM(y, sm.add_constant(np.ones_like(y)), family=sm.families.Poisson()).fit().llf\n",
    "    pseudo_r2_mcfadden = 1 - log_likelihood / ll_null\n",
    "    \n",
    "    print(\"Log-Likelihood:\", log_likelihood)\n",
    "    print(\"Pseudo R^2 (McFadden):\", pseudo_r2_mcfadden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdac4001-0408-4105-9ca2-a0fd923a38ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# export modeling results \n",
    "\n",
    "# Extract coefficients and p-values\n",
    "summary_model1 = baseline_qp_new.summary2().tables[1]\n",
    "summary_model2 = market_qp_new.summary2().tables[1]\n",
    "summary_model3 = governance_qp_new.summary2().tables[1]\n",
    "summary_model4 = statcap_qp_new.summary2().tables[1]\n",
    "summary_model5 = full_qp_new.summary2().tables[1]\n",
    "\n",
    "# Function to apply stars based on p-value thresholds\n",
    "def add_significance_stars(df):\n",
    "    def apply_stars(row):\n",
    "        coef = row['Coef.']\n",
    "        p_value = row['P>|z|']\n",
    "        # Apply stars based on p-value\n",
    "        if p_value < 0.001:\n",
    "            return f\"{coef:.3f}***\"\n",
    "        elif p_value < 0.01:\n",
    "            return f\"{coef:.3f}**\"\n",
    "        elif p_value < 0.051:\n",
    "            return f\"{coef:.3f}*\"\n",
    "        else:\n",
    "            return f\"{coef:.3f}\"\n",
    "    \n",
    "    df['Coef. (with stars)'] = df.apply(apply_stars, axis=1)\n",
    "    return df\n",
    "\n",
    "# Keep only the coefficients and p-values for each model and apply stars\n",
    "coefficients1 = add_significance_stars(summary_model1[['Coef.', 'P>|z|']]).reset_index(drop=True)\n",
    "coefficients2 = add_significance_stars(summary_model2[['Coef.', 'P>|z|']]).reset_index(drop=True)\n",
    "coefficients3 = add_significance_stars(summary_model3[['Coef.', 'P>|z|']]).reset_index(drop=True)\n",
    "coefficients4 = add_significance_stars(summary_model4[['Coef.', 'P>|z|']]).reset_index(drop=True)\n",
    "coefficients5 = add_significance_stars(summary_model5[['Coef.', 'P>|z|']]).reset_index(drop=True)\n",
    "\n",
    "# Combine the results from all five models side by side\n",
    "combined_results = pd.concat([coefficients1[['Coef. (with stars)']],\n",
    "                              coefficients2[['Coef. (with stars)']],\n",
    "                              coefficients3[['Coef. (with stars)']],\n",
    "                              coefficients4[['Coef. (with stars)']],\n",
    "                              coefficients5[['Coef. (with stars)']]], axis=1)\n",
    "\n",
    "# Rename the columns for clarity\n",
    "combined_results.columns = ['Model 1 Coef.', 'Model 2 Coef.', 'Model 3 Coef.', 'Model 4 Coef.', 'Model 5 Coef.']\n",
    "\n",
    "# Export to CSV or Excel for use in Word\n",
    "combined_results.to_excel('../results/quasi_poisson_models_results.xlsx')\n",
    "\n",
    "print(\"Model results with significance stars for five models exported successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a412e0-0988-4a27-983a-9dfe4d0d681e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_new_models = [baseline_qp_new, market_qp_new, governance_qp_new, statcap_qp_new, full_qp_new]\n",
    "\n",
    "for model in all_new_models:\n",
    "    print(check_overdispersion(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe170f1-9344-4b72-bf91-57da4cda821d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if 'median_corrup_cases', 'median_audit_cases' are correlated. YES\n",
    "# check if 'securityexp_pc', 'govexp_by_gdp' are correlated. NO\n",
    "# check if 'landsale_by_govrev', 'median_land_size' are correlated. YES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c48518-d10a-4ae0-95ec-ccf391e285d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def calculate_pvalues(df):\n",
    "    # Initialize an empty dataframe to store p-values\n",
    "    pvalues = pd.DataFrame(np.ones((df.shape[1], df.shape[1])), columns=df.columns, index=df.columns)\n",
    "\n",
    "    # Iterate over each pair of columns in the dataframe\n",
    "    for col1 in df.columns:\n",
    "        for col2 in df.columns:\n",
    "            if col1 != col2:  # Avoid calculating p-values for diagonal\n",
    "                corr, pval = pearsonr(df[col1], df[col2])\n",
    "                pvalues.loc[col1, col2] = pval\n",
    "    return pvalues\n",
    "\n",
    "# Calculate the p-values for the correlation matrix\n",
    "df_corr = df.drop(columns = ['province'])\n",
    "pvalue_matrix = calculate_pvalues(df_corr)\n",
    "\n",
    "# Select only the p-values less than 0.05\n",
    "significant_pvalues = pvalue_matrix[pvalue_matrix < 0.05]\n",
    "\n",
    "# Display the filtered p-values (NaN where p-values are >= 0.\n",
    "print(significant_pvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a04309-8854-4cb7-bd12-e2214c2ae1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a552a24-dd03-440e-b0a8-476eb742afc3",
   "metadata": {},
   "source": [
    "# Fitted values vs. true values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7561b0d1-26a5-4f7e-b41d-9471f02e9f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_fitted_vs_observed(y, models, model_names, province_names):\n",
    "    \"\"\"\n",
    "    Plots observed vs fitted values for multiple models in a 2-row, 3-column grid with province names.\n",
    "\n",
    "    Parameters:\n",
    "    - y: array-like, observed values.\n",
    "    - models: list of models, each with a `.fittedvalues` attribute.\n",
    "    - model_names: list of strings, names of the models.\n",
    "    - province_names: list of strings, province names corresponding to the data points.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    num_models = len(models)\n",
    "    rows, cols = 2, 3  # Define grid layout\n",
    "    \n",
    "    # Create a figure with subplots\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 10))  # Adjust size dynamically\n",
    "    axes = axes.flatten()  # Flatten the 2D array of axes for easy indexing\n",
    "\n",
    "    for i, (model, model_name) in enumerate(zip(models, model_names)):\n",
    "        fitted_values = model.fittedvalues  # Extract fitted values\n",
    "        \n",
    "        # Plot observed vs fitted values\n",
    "        axes[i].scatter(y, fitted_values, label=f'{model_name}')\n",
    "        axes[i].plot(y, y, '--', label='y = x')  # Reference line\n",
    "        \n",
    "        # # Annotate each point with its province name\n",
    "        # for obs, fit, province in zip(y, fitted_values, province_names):\n",
    "        #     axes[i].annotate(province, (obs, fit), fontsize=8, alpha=0.7)\n",
    "        \n",
    "        # Set plot details\n",
    "        axes[i].set_title(f'{model_name}')\n",
    "        axes[i].set_xlabel('Observed Values')\n",
    "        axes[i].set_ylabel('Fitted Values')\n",
    "        axes[i].legend()\n",
    "        axes[i].grid(True)\n",
    "\n",
    "    # Hide any unused subplots\n",
    "    for j in range(num_models, len(axes)):\n",
    "        axes[j].axis('off')  # Turn off axes for unused plots\n",
    "\n",
    "    # Adjust layout for better spacing\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the figure\n",
    "    plt.savefig('../results/fitted vs. observed plots.png')\n",
    "\n",
    "\n",
    "# Assuming y is observed values, models is your list of models, and province_names is the list of province names\n",
    "all_new_models = [baseline_qp_new, market_qp_new, governance_qp_new, statcap_qp_new, full_qp_new]\n",
    "model_names = ['Model 0', 'Model 1', 'Model 2', 'Model 3', 'Model 4']\n",
    "province_names = df['province'] # Replace with actual names\n",
    "\n",
    "plot_fitted_vs_observed(y, all_new_models, model_names, province_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb9d2d4-1de5-4145-a571-c25801e4039f",
   "metadata": {},
   "source": [
    "# Check specific variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59879b45-f141-44f6-87ac-9a14190961ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# land sale by gov rev\n",
    "plt.scatter(df['landsale_by_govrev'], y)\n",
    "\n",
    "plt.ylabel(\"num of violence\")\n",
    "plt.xlabel(\"land sale to gov revenue\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e868f50-91b4-48d7-91b8-ae31fb460804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# land acquisition size\n",
    "plt.scatter(df['median_land_size'], y)\n",
    "\n",
    "# Add labels to each point\n",
    "for i, label in enumerate(df['province']):  \n",
    "    plt.text(df['median_land_size'][i], y[i], str(label), fontsize=9, ha='right')\n",
    "\n",
    "\n",
    "plt.title('Land acquisition size vs. number of outsourced violence')\n",
    "plt.ylabel(\"number of outsourced violence\")\n",
    "plt.xlabel(\"land acquisition size\")\n",
    "plt.savefig('../results/land_size_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53c5757-30a2-4069-a844-353ad8b13eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Pearson correlation coefficient and p-value\n",
    "corr_coeff, p_value = pearsonr(df['land_size_square'], y)\n",
    "\n",
    "print(\"Correlation Coefficient:\", corr_coeff)\n",
    "print(\"P-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa6ba23-2a6c-41ad-b676-6c01c863b43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = ['Henan', 'Hebei', 'Shaanxi']\n",
    "df_test = df[~df['province'].isin(outliers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cf07ce-6dd2-4236-9dac-daf3e2d0ad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Pearson correlation coefficient and p-value\n",
    "corr_coeff, p_value = pearsonr(df_test['median_land_size'], df_test['median_corrup_cases'])\n",
    "\n",
    "print(\"Correlation Coefficient:\", corr_coeff)\n",
    "print(\"P-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f011cda7-e78e-4653-82b2-3741567a820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corruption vs. audit\n",
    "\n",
    "plt.scatter(df['median_audit_cases'], y)\n",
    "\n",
    "# Add labels to each point\n",
    "for i, label in enumerate(df['province']):  \n",
    "    plt.text(df['median_audit_cases'][i], y[i], str(label), fontsize=9, ha='right')\n",
    "\n",
    "\n",
    "plt.title('Audit cases vs. Anti-corruption cases')\n",
    "plt.ylabel(\"Anti-corruption cases\")\n",
    "plt.xlabel(\"Audit cases\")\n",
    "# plt.savefig('../results/land_size_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12656f9b-f20a-45c1-b54d-ee220c2abc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Pearson correlation coefficient and p-value\n",
    "corr_coeff, p_value = pearsonr(df['median_audit_cases'], df['median_corrup_cases'])\n",
    "\n",
    "print(\"Correlation Coefficient:\", corr_coeff)\n",
    "print(\"P-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649dabe7-53cc-4f61-8d33-ee59f02a0a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4e112c-df00-4ad7-ac64-cddb1dadada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fiscal revenue vs. y\n",
    "\n",
    "plt.scatter(df['govrev_by_gdp'], y)\n",
    "\n",
    "# Add labels to each point\n",
    "for i, label in enumerate(df['province']):  \n",
    "    plt.text(df['govrev_by_gdp'][i], y[i], str(label), fontsize=9, ha='right')\n",
    "\n",
    "\n",
    "plt.title('Fiscal revenue by gdp vs. number of violent cases')\n",
    "plt.ylabel(\"# of violence\")\n",
    "plt.xlabel(\"Fiscal revenue by gdp\")\n",
    "plt.savefig('../results/fiscal_revenue_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfe037c-8707-453c-bb96-462efcae9db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Pearson correlation coefficient and p-value\n",
    "corr_coeff, p_value = pearsonr(df['reciprocal_govrev'], y)\n",
    "\n",
    "print(\"Correlation Coefficient:\", corr_coeff)\n",
    "print(\"P-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98950533-eb67-4a57-9cbb-df7a05231db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfe4bbf-5ed0-45db-b350-01be71e57c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = ['gdp_pc', 'securityexp_pc', 'govrev_by_gdp', 'cpi', 'unemp_rate',\n",
    "          'migpop_by_totalpop', 'median_audit_cases', 'median_corrup_cases', 'median_land_size']\n",
    "\n",
    "# Create a single figure to hold all subplots\n",
    "fig, axes = plt.subplots(len(x_list), 1, figsize=(10, len(x_list) * 5))\n",
    "\n",
    "for i, x in enumerate(x_list):\n",
    "    ax = axes[i]\n",
    "    ax.scatter(df[x], y)\n",
    "\n",
    "    # Add labels to each point\n",
    "    for j, label in enumerate(df['province']):\n",
    "        ax.text(df[x][j], y[j], str(label), fontsize=9, ha='right')\n",
    "\n",
    "    # Set labels for axes\n",
    "    ax.set_xlabel(x)\n",
    "    ax.set_ylabel(\"# of violence\")\n",
    "    ax.set_title(f'Scatter plot of {x} vs. # of violence')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save all plots in one PNG file\n",
    "plt.savefig('../results/all_scatter_plots.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd31634-b74c-4a61-9385-5ff21b9875b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
